# æ•°æ®é›†ä¸‹è½½å’Œç¼“å­˜ç®¡ç†æŒ‡å—

æœ¬æ–‡æ¡£æä¾›å®Œæ•´çš„æ•°æ®é›†ä¸‹è½½ã€ç¼“å­˜ç®¡ç†å’Œæ•…éšœæ’æŸ¥æŒ‡å—ã€‚

---

## ğŸ“¦ æ”¯æŒçš„æ•°æ®é›†

| æ•°æ®é›† | ç”¨é€” | å¤§å° | æ¨èç¨‹åº¦ |
|--------|------|------|----------|
| WikiText-2 | PPLè¯„ä¼° | ~4MB | â­â­â­â­â­ æœ€æ¨è |
| PTB | PPLè¯„ä¼° | ~5MB | â­â­â­ å¯é€‰ |
| C4 | PPLè¯„ä¼° | ~365GB (å…¨é›†) | â­â­ ä»…é™å®Œæ•´æµ‹è¯• |
| HellaSwag/PIQAç­‰ | Zero-shot | è‡ªåŠ¨ä¸‹è½½ | â­â­â­â­â­ å¿…éœ€ |

---

## ğŸ”§ é—®é¢˜1ï¼šPTBæ•°æ®é›†æ— æ³•ä¸‹è½½

### é”™è¯¯ä¿¡æ¯
```
Dataset 'ptb-text-only' doesn't exist on the Hub or cannot be accessed.
```

### åŸå› 
PTBæ•°æ®é›†åœ¨HuggingFace Hubä¸Šæœ‰å¤šä¸ªç‰ˆæœ¬ï¼Œä¸”éƒ¨åˆ†å·²è¢«ç§»é™¤æˆ–é‡å‘½åã€‚

### è§£å†³æ–¹æ¡ˆ

#### æ–¹æ¡ˆAï¼šè·³è¿‡PTBï¼Œåªç”¨WikiText-2ï¼ˆæ¨èï¼‰
```bash
# åªä½¿ç”¨WikiText-2è¯„ä¼°ï¼ˆæœ€å¸¸ç”¨ï¼Œè®ºæ–‡ä¸­æ™®éä½¿ç”¨ï¼‰
python evaluation/run_evaluation.py \
    --model_path your_model.bin \
    --metrics ppl \
    --ppl_datasets wikitext2 \
    --output results.json
```

**ç†ç”±**ï¼šWikiText-2æ˜¯æœ€æ ‡å‡†çš„PPL benchmarkï¼Œå‡ ä¹æ‰€æœ‰è®ºæ–‡éƒ½ä½¿ç”¨å®ƒã€‚PTBæ˜¯è¡¥å……æ€§æŒ‡æ ‡ã€‚

#### æ–¹æ¡ˆBï¼šæ‰‹åŠ¨ä¸‹è½½PTB
```bash
# 1. åˆ›å»ºæ•°æ®ç›®å½•
mkdir -p ~/.cache/huggingface/datasets/ptb_manual

# 2. ä¸‹è½½PTBæ•°æ®ï¼ˆéœ€è¦LDCè®¸å¯ï¼Œæˆ–ä½¿ç”¨å¼€æºç‰ˆæœ¬ï¼‰
# æ–¹æ³•1: ä»LDCå®˜æ–¹ï¼ˆéœ€è¦è®¸å¯ï¼‰
wget https://catalog.ldc.upenn.edu/LDC99T42

# æ–¹æ³•2: ä½¿ç”¨å¼€æºç‰ˆæœ¬ï¼ˆæ¨èï¼‰
git clone https://github.com/tomsercu/lstm
cp lstm/data/ptb.test.txt ~/.cache/huggingface/datasets/ptb_manual/
```

#### æ–¹æ¡ˆCï¼šä½¿ç”¨æ›¿ä»£æ•°æ®é›†
å¦‚æœPTBå¿…éœ€ï¼Œå¯ä½¿ç”¨ä»¥ä¸‹æ›¿ä»£ï¼š
```python
# ä¿®æ”¹ LLMPruner/evaluator/ppl.py
# ä½¿ç”¨ 'lambada' ä½œä¸ºPTBæ›¿ä»£
dataset = load_dataset('lambada', split='test')
```

---

## ğŸ”§ é—®é¢˜2ï¼šC4æ•°æ®é›†åŠ è½½å¤±è´¥

### é”™è¯¯ä¿¡æ¯
```
Dataset scripts are no longer supported, but found c4.py
```

### åŸå› 
HuggingFace Datasetsåº“æ›´æ–°åï¼Œä¸å†æ”¯æŒlegacy loading scriptsã€‚C4éœ€è¦ä½¿ç”¨æ–°è·¯å¾„ã€‚

### è§£å†³æ–¹æ¡ˆ

#### æ–¹æ¡ˆAï¼šä½¿ç”¨WikiText-2æ›¿ä»£ï¼ˆå¼ºçƒˆæ¨èï¼‰
```bash
# C4æ•°æ®é›†å·¨å¤§ï¼ˆ365GBï¼‰ä¸”ä¸‹è½½æ…¢ï¼ŒWikiText-2å®Œå…¨å¤Ÿç”¨
python evaluation/run_evaluation.py \
    --model_path your_model.bin \
    --metrics ppl \
    --ppl_datasets wikitext2 \
    --output results.json
```

#### æ–¹æ¡ˆBï¼šä½¿ç”¨æ–°ç‰ˆC4åŠ è½½è·¯å¾„
å·²åœ¨ä»£ç ä¸­ä¿®å¤ï¼Œä½¿ç”¨ `allenai/c4` è·¯å¾„ï¼š
```bash
# ä½¿ç”¨æ–°ç‰ˆC4ï¼ˆä¼šè‡ªåŠ¨å°è¯•æ–°è·¯å¾„ï¼‰
python evaluation/run_evaluation.py \
    --model_path your_model.bin \
    --metrics ppl \
    --ppl_datasets wikitext2,c4 \
    --output results.json
```

**æ³¨æ„**ï¼šå³ä½¿ä½¿ç”¨æ–°è·¯å¾„ï¼ŒC4ä¹Ÿä¼šä¸‹è½½è¾ƒå¤§æ–‡ä»¶ï¼ˆ~10GB for validationï¼‰ï¼Œé¦–æ¬¡è¿è¡Œè¾ƒæ…¢ã€‚

#### æ–¹æ¡ˆCï¼šä½¿ç”¨C4å­é›†
```python
# ä¿®æ”¹ä»£ç åªä½¿ç”¨tiny C4 subset
from datasets import load_dataset
dataset = load_dataset('allenai/c4', 'en', split='validation[:1%]', streaming=False)
```

---

## ğŸ”§ é—®é¢˜3ï¼šZero-shotè¯„ä¼°æ•°æ®é›†ç¼“å­˜æŸå

### é”™è¯¯ä¿¡æ¯
```
NonMatchingSplitsSizesError: expected SplitInfo(...num_examples=39905...)
recorded: SplitInfo(...num_examples=0...)
```

### åŸå› 
HuggingFace datasetsç¼“å­˜æŸåæˆ–éƒ¨åˆ†ä¸‹è½½å¤±è´¥ï¼Œå¯¼è‡´æ•°æ®é›†splitsä¿¡æ¯ä¸åŒ¹é…ã€‚

### è§£å†³æ–¹æ¡ˆ

#### æ–¹æ¡ˆAï¼šæ¸…ç†æŸåçš„ç¼“å­˜ï¼ˆæ¨èï¼‰
```bash
# 1. æŸ¥çœ‹ç¼“å­˜ä½ç½®
echo "æ•°æ®é›†ç¼“å­˜: ~/.cache/huggingface/datasets/"

# 2. åˆ é™¤æŸåçš„æ•°æ®é›†ç¼“å­˜
rm -rf ~/.cache/huggingface/datasets/hellaswag
rm -rf ~/.cache/huggingface/datasets/piqa
rm -rf ~/.cache/huggingface/datasets/winogrande

# 3. é‡æ–°è¿è¡Œè¯„ä¼°ï¼ˆä¼šè‡ªåŠ¨é‡æ–°ä¸‹è½½ï¼‰
python evaluation/run_evaluation.py \
    --model_path your_model.bin \
    --metrics zeroshot \
    --output results.json
```

#### æ–¹æ¡ˆBï¼šå®Œå…¨æ¸…ç†æ‰€æœ‰ç¼“å­˜
```bash
# è­¦å‘Šï¼šä¼šåˆ é™¤æ‰€æœ‰å·²ä¸‹è½½çš„æ•°æ®é›†
rm -rf ~/.cache/huggingface/datasets/*

# é‡æ–°è¿è¡Œ
python evaluation/run_evaluation.py \
    --model_path your_model.bin \
    --metrics zeroshot \
    --output results.json
```

#### æ–¹æ¡ˆCï¼šä½¿ç”¨æ–°çš„ç¼“å­˜ç›®å½•
```bash
# è®¾ç½®ç¯å¢ƒå˜é‡ä½¿ç”¨æ–°ç¼“å­˜
export HF_DATASETS_CACHE="/path/to/new/cache"

# è¿è¡Œè¯„ä¼°
python evaluation/run_evaluation.py \
    --model_path your_model.bin \
    --metrics zeroshot \
    --output results.json
```

#### æ–¹æ¡ˆDï¼šå¿½ç•¥ç¼“å­˜éªŒè¯ï¼ˆä¸æ¨èï¼‰
```python
# ä¿®æ”¹ evaluation/metrics/performance.py
# åœ¨load_datasetè°ƒç”¨ä¸­æ·»åŠ 
dataset = load_dataset(..., verification_mode='no_checks')
```

---

## ğŸ“‚ æ•°æ®é›†ç¼“å­˜ç®¡ç†

### æŸ¥çœ‹ç¼“å­˜å ç”¨
```bash
# æŸ¥çœ‹æ•°æ®é›†ç¼“å­˜å¤§å°
du -sh ~/.cache/huggingface/datasets/

# æŸ¥çœ‹å„æ•°æ®é›†å ç”¨
du -sh ~/.cache/huggingface/datasets/*
```

### æ¸…ç†ç‰¹å®šæ•°æ®é›†
```bash
# åªæ¸…ç†C4ï¼ˆå¦‚æœä¸éœ€è¦ï¼‰
rm -rf ~/.cache/huggingface/datasets/c4

# åªæ¸…ç†PTBï¼ˆå¦‚æœæœ‰é—®é¢˜ï¼‰
rm -rf ~/.cache/huggingface/datasets/ptb*
```

### é¢„ä¸‹è½½æ‰€æœ‰æ•°æ®é›†
```bash
# åˆ›å»ºé¢„ä¸‹è½½è„šæœ¬
python -c "
from datasets import load_dataset

# ä¸‹è½½WikiText-2
print('ä¸‹è½½ WikiText-2...')
load_dataset('wikitext', 'wikitext-2-raw-v1', split='test')

# ä¸‹è½½Zero-shotæ•°æ®é›†
print('ä¸‹è½½ HellaSwag...')
load_dataset('Rowan/hellaswag', split='validation')

print('ä¸‹è½½ PIQA...')
load_dataset('piqa', split='validation')

print('ä¸‹è½½ WinoGrande...')
load_dataset('winogrande', 'winogrande_xl', split='validation')

print('ä¸‹è½½ ARC-Easy...')
load_dataset('ai2_arc', 'ARC-Easy', split='test')

print('ä¸‹è½½ BoolQ...')
load_dataset('google/boolq', split='validation')

print('âœ“ æ‰€æœ‰æ•°æ®é›†ä¸‹è½½å®Œæˆ')
"
```

---

## ğŸš€ æ¨èé…ç½®

### æœ€å°é…ç½®ï¼ˆå¿«é€Ÿæµ‹è¯•ï¼‰
```bash
# åªç”¨WikiText-2 PPLï¼Œè·³è¿‡Zero-shot
python evaluation/run_evaluation.py \
    --model_path your_model.bin \
    --metrics ppl,speed,memory \
    --ppl_datasets wikitext2 \
    --output results.json
```

### æ ‡å‡†é…ç½®ï¼ˆè®ºæ–‡è¯„ä¼°ï¼‰
```bash
# WikiText-2 + Zero-shotï¼ˆ5ä¸ªä»»åŠ¡ï¼‰
python evaluation/run_evaluation.py \
    --model_path your_model.bin \
    --metrics ppl,zeroshot,speed,memory \
    --ppl_datasets wikitext2 \
    --zeroshot_tasks hellaswag,piqa,winogrande,arc_easy,boolq \
    --output results.json
```

### å®Œæ•´é…ç½®ï¼ˆè¯¦å°½è¯„ä¼°ï¼‰
```bash
# æ‰€æœ‰æ•°æ®é›† + æ•ˆç‡æŒ‡æ ‡
python evaluation/run_evaluation.py \
    --model_path your_model.bin \
    --metrics all \
    --ppl_datasets wikitext2 \
    --output results.json

# æ³¨æ„ï¼šè·³è¿‡PTBå’ŒC4ï¼Œå®ƒä»¬ä¸ç¨³å®šä¸”éå¿…éœ€
```

---

## â“ å¸¸è§é—®é¢˜

### Q: WikiText-2ä¸‹è½½å¾ˆæ…¢æ€ä¹ˆåŠï¼Ÿ
A: ä½¿ç”¨é•œåƒæˆ–è®¾ç½®ä»£ç†ï¼š
```bash
# ä½¿ç”¨HFé•œåƒï¼ˆå›½å†…ï¼‰
export HF_ENDPOINT=https://hf-mirror.com

# æˆ–ä½¿ç”¨ä»£ç†
export https_proxy=http://your-proxy:port
```

### Q: æ•°æ®é›†ç¼“å­˜å ç”¨å¤ªå¤§æ€ä¹ˆåŠï¼Ÿ
A:
1. åªä¿ç•™WikiText-2ï¼ˆ~4MBï¼‰
2. åˆ é™¤C4ï¼ˆå¦‚æœå·²ä¸‹è½½ï¼Œ~10GBï¼‰
3. å®šæœŸæ¸…ç†ä¸ç”¨çš„æ•°æ®é›†

### Q: Zero-shotè¯„ä¼°ç‰¹åˆ«æ…¢æ€ä¹ˆåŠï¼Ÿ
A:
1. å‡å°‘ä»»åŠ¡æ•°é‡ï¼šåªç”¨ `hellaswag,piqa` è€Œéå…¨éƒ¨5ä¸ª
2. ä½¿ç”¨æ›´å°çš„batch_size
3. é¦–æ¬¡è¿è¡Œè¾ƒæ…¢ï¼ˆéœ€ä¸‹è½½æ•°æ®é›†ï¼‰ï¼Œåç»­ä¼šå¿«å¾ˆå¤š

### Q: æ˜¯å¦éœ€è¦æ‰‹åŠ¨ä¸‹è½½æ‰€æœ‰æ•°æ®é›†ï¼Ÿ
A: **ä¸éœ€è¦**ã€‚datasetsåº“ä¼šè‡ªåŠ¨ä¸‹è½½å¹¶ç¼“å­˜ã€‚åªæœ‰åœ¨é‡åˆ°ç½‘ç»œé—®é¢˜æˆ–ç¼“å­˜æŸåæ—¶æ‰éœ€è¦æ‰‹åŠ¨å¹²é¢„ã€‚

---

## ğŸ“ æ•°æ®é›†æ¥æºæ±‡æ€»

| æ•°æ®é›† | HuggingFaceè·¯å¾„ | å®˜æ–¹æ¥æº |
|--------|----------------|----------|
| WikiText-2 | `wikitext` / `wikitext-2-raw-v1` | [Link](https://blog.salesforceairesearch.com/the-wikitext-long-term-dependency-language-modeling-dataset/) |
| PTB | `ptb_text_only` (å·²ç§»é™¤) | [LDC](https://catalog.ldc.upenn.edu/LDC99T42) |
| C4 | `allenai/c4` / `en` | [AllenAI](https://github.com/allenai/allennlp) |
| HellaSwag | `Rowan/hellaswag` | [Paper](https://arxiv.org/abs/1905.07830) |
| PIQA | `piqa` | [Paper](https://arxiv.org/abs/1911.11641) |
| WinoGrande | `winogrande` / `winogrande_xl` | [Paper](https://arxiv.org/abs/1907.10641) |
| ARC | `ai2_arc` / `ARC-Easy` | [Paper](https://arxiv.org/abs/1803.05457) |
| BoolQ | `google/boolq` | [Paper](https://arxiv.org/abs/1905.10044) |

---

## ğŸ› ï¸ æ•…éšœæ’æŸ¥æµç¨‹

é‡åˆ°æ•°æ®é›†é—®é¢˜æ—¶ï¼ŒæŒ‰æ­¤æµç¨‹æ’æŸ¥ï¼š

1. **æ£€æŸ¥ç½‘ç»œè¿æ¥**
   ```bash
   ping huggingface.co
   ```

2. **æ£€æŸ¥ç¼“å­˜çŠ¶æ€**
   ```bash
   ls -lh ~/.cache/huggingface/datasets/
   ```

3. **æ¸…ç†æŸåç¼“å­˜**
   ```bash
   rm -rf ~/.cache/huggingface/datasets/[problem_dataset]
   ```

4. **ä½¿ç”¨æœ€å°é…ç½®æµ‹è¯•**
   ```bash
   python evaluation/run_evaluation.py \
       --model_path your_model.bin \
       --metrics ppl \
       --ppl_datasets wikitext2 \
       --output test.json
   ```

5. **å¦‚ä»æœ‰é—®é¢˜ï¼Œè·³è¿‡è¯¥æ•°æ®é›†**
   ```bash
   # åªç”¨WikiText-2å³å¯ï¼ŒPTB/C4æ˜¯å¯é€‰çš„
   --ppl_datasets wikitext2
   ```

---

**æœ€åå»ºè®®**ï¼šå¯¹äºå¤§å¤šæ•°è®ºæ–‡å’Œå®éªŒï¼Œ**åªä½¿ç”¨WikiText-2è¿›è¡ŒPPLè¯„ä¼°å·²å®Œå…¨è¶³å¤Ÿ**ã€‚PTBå’ŒC4æ˜¯è¡¥å……æ€§æŒ‡æ ‡ï¼Œéå¿…éœ€ã€‚
