# è¯„ä¼°æ¨¡å—å¿«é€Ÿå¼€å§‹æŒ‡å—

é’ˆå¯¹æ‚¨é‡åˆ°çš„ä¸‰ä¸ªé—®é¢˜çš„å¿«é€Ÿè§£å†³æ–¹æ¡ˆã€‚

---

## âš¡ é—®é¢˜1ï¼šGPUè‡ªåŠ¨é€‰æ‹©

### è§£å†³æ–¹æ¡ˆ
ä½¿ç”¨ `--auto_select_gpu` å‚æ•°è‡ªåŠ¨é€‰æ‹©å‰©ä½™æ˜¾å­˜æœ€å¤šçš„GPUï¼š

```bash
python evaluation/run_evaluation.py \
    --auto_select_gpu \
    --model_path prune_log/xxx/pytorch_model.bin \
    --metrics ppl,speed,memory \
    --output results/ours.json
```

**è¯´æ˜**ï¼š
- ä¼šè‡ªåŠ¨æ£€æµ‹æ‰€æœ‰GPUçš„å‰©ä½™æ˜¾å­˜
- é€‰æ‹©å‰©ä½™æ˜¾å­˜æœ€å¤§çš„GPU
- è¦†ç›– `--device` å‚æ•°

### æ‰‹åŠ¨æŒ‡å®šGPUï¼ˆæ›¿ä»£æ–¹æ¡ˆï¼‰
```bash
# æŒ‡å®šGPU 0
python evaluation/run_evaluation.py \
    --device cuda:0 \
    --model_path ... \
    --output results.json

# æŒ‡å®šGPU 3
python evaluation/run_evaluation.py \
    --device cuda:3 \
    --model_path ... \
    --output results.json
```

---

## âš¡ é—®é¢˜2ï¼šPTBå’ŒC4æ•°æ®é›†æ— æ³•ä¸‹è½½

### âœ… æ¨èæ–¹æ¡ˆï¼šåªç”¨WikiText-2
å¯¹äºå¤§å¤šæ•°è®ºæ–‡ï¼Œ**WikiText-2å·²å®Œå…¨è¶³å¤Ÿ**ï¼ŒPTBå’ŒC4æ˜¯å¯é€‰çš„ï¼š

```bash
python evaluation/run_evaluation.py \
    --auto_select_gpu \
    --model_path prune_log/xxx/pytorch_model.bin \
    --metrics ppl,speed,memory \
    --ppl_datasets wikitext2 \
    --output results/ours.json
```

**ç†ç”±**ï¼š
- WikiText-2æ˜¯æœ€æ ‡å‡†çš„PPL benchmark
- å‡ ä¹æ‰€æœ‰LLMè®ºæ–‡éƒ½ä½¿ç”¨WikiText-2
- PTBå’ŒC4ä¸‹è½½ä¸ç¨³å®šä¸”éå¿…éœ€

### å¦‚æœå¿…é¡»ä½¿ç”¨PTB/C4
å‚è§è¯¦ç»†æ–‡æ¡£ï¼š`evaluation/docs/dataset_download.md`

---

## âš¡ é—®é¢˜3ï¼šZero-shotè¯„ä¼°ç¼“å­˜æŸå

### é”™è¯¯ä¿¡æ¯
```
NonMatchingSplitsSizesError: expected SplitInfo(...num_examples=39905...)
recorded: SplitInfo(...num_examples=0...)
```

### è§£å†³æ–¹æ¡ˆï¼šæ¸…ç†æŸåçš„ç¼“å­˜

#### æ–¹æ³•Aï¼šä½¿ç”¨æ¸…ç†å·¥å…·ï¼ˆæ¨èï¼‰
```bash
# æ¸…ç†Zero-shotç›¸å…³æ•°æ®é›†ï¼ˆhellaswag, piqaç­‰ï¼‰
python evaluation/clean_dataset_cache.py --zeroshot

# æ¸…ç†PPLç›¸å…³æ•°æ®é›†ï¼ˆwikitext, ptb, c4ï¼‰
python evaluation/clean_dataset_cache.py --ppl

# åˆ—å‡ºæ‰€æœ‰ç¼“å­˜
python evaluation/clean_dataset_cache.py --list

# æ¸…ç†ç‰¹å®šæ•°æ®é›†
python evaluation/clean_dataset_cache.py --dataset hellaswag
```

#### æ–¹æ³•Bï¼šæ‰‹åŠ¨æ¸…ç†ï¼ˆå¿«é€Ÿï¼‰
```bash
# åˆ é™¤æŸåçš„æ•°æ®é›†ç¼“å­˜
rm -rf ~/.cache/huggingface/datasets/hellaswag
rm -rf ~/.cache/huggingface/datasets/piqa
rm -rf ~/.cache/huggingface/datasets/winogrande
rm -rf ~/.cache/huggingface/datasets/ai2_arc
rm -rf ~/.cache/huggingface/datasets/google___boolq

# é‡æ–°è¿è¡Œè¯„ä¼°ï¼ˆä¼šè‡ªåŠ¨é‡æ–°ä¸‹è½½ï¼‰
python evaluation/run_evaluation.py \
    --auto_select_gpu \
    --model_path your_model.bin \
    --metrics zeroshot \
    --output results.json
```

#### æ–¹æ³•Cï¼šå®Œå…¨æ¸…ç†ï¼ˆæœ€å½»åº•ï¼‰
```bash
# âš ï¸ è­¦å‘Šï¼šåˆ é™¤æ‰€æœ‰æ•°æ®é›†ç¼“å­˜
python evaluation/clean_dataset_cache.py --all
```

---

## ğŸš€ å®Œæ•´è¯„ä¼°æµç¨‹

### æ­¥éª¤1ï¼šè¯„ä¼°å‰ªæåçš„æ¨¡å‹
```bash
python evaluation/run_evaluation.py \
    --auto_select_gpu \
    --model_path prune_log/ppl_search_20251118_005448_ratio_0.7_9.3_freeze_8/pytorch_model.bin \
    --metrics ppl,speed,memory \
    --ppl_datasets wikitext2 \
    --output results/ours.json
```

### æ­¥éª¤2ï¼šè¯„ä¼°åŸå§‹æ¨¡å‹
```bash
python evaluation/run_evaluation.py \
    --auto_select_gpu \
    --model_path /newdata/LLMs/Llama-3-8B-Instruct \
    --metrics ppl,speed,memory \
    --ppl_datasets wikitext2 \
    --output results/original.json
```

### æ­¥éª¤3ï¼šæ·»åŠ Zero-shotè¯„ä¼°ï¼ˆå¯é€‰ï¼‰

**é¦–å…ˆæ¸…ç†ç¼“å­˜**ï¼ˆå¦‚æœä¹‹å‰é‡åˆ°é”™è¯¯ï¼‰ï¼š
```bash
python evaluation/clean_dataset_cache.py --zeroshot
```

**ç„¶åè¿è¡ŒZero-shot**ï¼š
```bash
# å‰ªææ¨¡å‹ï¼ˆ.binæ–‡ä»¶ç›´æ¥æ”¯æŒï¼‰
python evaluation/run_evaluation.py \
    --auto_select_gpu \
    --model_path prune_log/xxx/pytorch_model.bin \
    --metrics zeroshot \
    --zeroshot_tasks hellaswag,piqa,winogrande \
    --output results/ours_zeroshot.json

# åŸå§‹æ¨¡å‹ï¼ˆHFæ ¼å¼ï¼‰
python evaluation/run_evaluation.py \
    --auto_select_gpu \
    --model_path /newdata/LLMs/Llama-3-8B-Instruct \
    --metrics zeroshot \
    --zeroshot_tasks hellaswag,piqa,winogrande \
    --output results/original_zeroshot.json
```

### æ­¥éª¤4ï¼šç”Ÿæˆå¯¹æ¯”è¡¨
```bash
python evaluation/run_evaluation.py \
    --compare \
    --model_paths results/original.json,results/ours.json \
    --output results/comparison.md
```

---

## ğŸ“Š æ¨èçš„æœ€å°è¯„ä¼°é…ç½®

å¯¹äºè®ºæ–‡å’Œå®éªŒï¼Œä»¥ä¸‹é…ç½®å·²å®Œå…¨è¶³å¤Ÿï¼š

```bash
# è¯„ä¼°å‰ªææ¨¡å‹
python evaluation/run_evaluation.py \
    --auto_select_gpu \
    --model_path prune_log/xxx/pytorch_model.bin \
    --metrics ppl,speed,memory \
    --ppl_datasets wikitext2 \
    --output results/ours.json

# è¯„ä¼°åŸå§‹æ¨¡å‹
python evaluation/run_evaluation.py \
    --auto_select_gpu \
    --model_path /newdata/LLMs/Llama-3-8B-Instruct \
    --metrics ppl,speed,memory \
    --ppl_datasets wikitext2 \
    --output results/original.json

# ç”Ÿæˆå¯¹æ¯”
python evaluation/run_evaluation.py \
    --compare \
    --model_paths results/original.json,results/ours.json \
    --output results/comparison.md
```

**åŒ…å«çš„æŒ‡æ ‡**ï¼š
- âœ… PPL (WikiText-2) - è¯­è¨€å»ºæ¨¡èƒ½åŠ›
- âœ… å‚æ•°é‡ - å‹ç¼©ç‡
- âœ… æ¨ç†é€Ÿåº¦ (tokens/s) - æ•ˆç‡æå‡
- âœ… GPUæ˜¾å­˜å ç”¨ - èµ„æºèŠ‚çœ

**è¿™äº›æŒ‡æ ‡è¶³ä»¥è¯æ˜æ‚¨çš„å‰ªææ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼**

---

## ğŸ” æ•…éšœæ’æŸ¥

### é—®é¢˜ï¼šGPUè‡ªåŠ¨é€‰æ‹©ä¸å·¥ä½œ
```bash
# æ£€æŸ¥nvidia-smiæ˜¯å¦å¯ç”¨
nvidia-smi

# å¦‚æœä¸å¯ç”¨ï¼Œæ‰‹åŠ¨æŒ‡å®šGPU
python evaluation/run_evaluation.py --device cuda:0 ...
```

### é—®é¢˜ï¼šæ•°æ®é›†ä¸‹è½½å¾ˆæ…¢
```bash
# ä½¿ç”¨HuggingFaceé•œåƒï¼ˆå›½å†…ï¼‰
export HF_ENDPOINT=https://hf-mirror.com

# æˆ–ä½¿ç”¨ä»£ç†
export https_proxy=http://your-proxy:port
```

### é—®é¢˜ï¼šZero-shotä¸€ç›´å¤±è´¥
```bash
# 1. å®Œå…¨æ¸…ç†ç¼“å­˜
python evaluation/clean_dataset_cache.py --all

# 2. åªè¯„ä¼°PPLï¼ˆè·³è¿‡Zero-shotï¼‰
python evaluation/run_evaluation.py \
    --auto_select_gpu \
    --model_path your_model.bin \
    --metrics ppl,speed,memory \
    --ppl_datasets wikitext2 \
    --output results.json
```

### é—®é¢˜ï¼šOOMé”™è¯¯
```bash
# ä½¿ç”¨force_single_deviceé¿å…å¤šGPUé—®é¢˜
# ä»£ç å·²è‡ªåŠ¨å¤„ç†ï¼Œä½†å¦‚æœä»æœ‰é—®é¢˜ï¼š

# 1. å‡å°‘batch size
--speed_samples 20  # é»˜è®¤50

# 2. ä½¿ç”¨æ›´å¤§çš„GPU
--device cuda:0  # é€‰æ‹©æ˜¾å­˜æ›´å¤§çš„GPU

# 3. è·³è¿‡speedæµ‹è¯•
--metrics ppl,memory  # ä¸æµ‹è¯•speed
```

---

## ğŸ“š æ›´å¤šæ–‡æ¡£

- å®Œæ•´è¯„ä¼°æŒ‡å—ï¼š`evaluation/README.md`
- æ•°æ®é›†ä¸‹è½½è¯¦è§£ï¼š`evaluation/docs/dataset_download.md`
- é¡¹ç›®æ€»è§ˆï¼š`CLAUDE.md`

---

## ğŸ’¡ å…³é”®è¦ç‚¹æ€»ç»“

1. **GPUé€‰æ‹©**ï¼šä½¿ç”¨ `--auto_select_gpu` è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜GPU
2. **æ•°æ®é›†**ï¼šåªç”¨ `--ppl_datasets wikitext2` å³å¯ï¼ŒPTB/C4å¯é€‰
3. **ç¼“å­˜é—®é¢˜**ï¼šç”¨ `python evaluation/clean_dataset_cache.py --zeroshot` æ¸…ç†
4. **.binæ–‡ä»¶**ï¼šå‰ªææ¨¡å‹çš„.binæ–‡ä»¶**ç›´æ¥æ”¯æŒæ‰€æœ‰è¯„ä¼°**ï¼Œæ— éœ€è½¬æ¢

**ç°åœ¨å°±å¯ä»¥å¼€å§‹å®Œæ•´è¯„ä¼°äº†ï¼** ğŸ‰
