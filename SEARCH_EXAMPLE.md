# è‡ªåŠ¨PPLä¼˜åŒ–æœç´¢ - ä½¿ç”¨ç¤ºä¾‹

æœ¬æ–‡æ¡£æä¾› `search_optimal_distribution.py` çš„è¯¦ç»†ä½¿ç”¨ç¤ºä¾‹å’Œæœ€ä½³å®è·µã€‚

## ç®—æ³•æ¦‚è¿°

æœ¬è„šæœ¬é‡‡ç”¨**æ™ºèƒ½åŒå‘æœç´¢ + æ—©åœ**ç­–ç•¥ï¼Œæ”¯æŒ**ä¸¤é˜¶æ®µæˆ–ä¸‰é˜¶æ®µè´ªå¿ƒæœç´¢**ï¼Œç›¸æ¯”ä¼ ç»Ÿçš„çº¿æ€§æœç´¢ï¼Œå¯èŠ‚çœ30-50%çš„æµ‹è¯•æ—¶é—´ã€‚

### æœç´¢ç­–ç•¥

#### ä¸¤é˜¶æ®µæœç´¢ï¼ˆé»˜è®¤ï¼‰
1. **é˜¶æ®µ1ï¼šç²—ç²’åº¦åˆ†å¸ƒæœç´¢**ï¼ˆæ­¥é•¿=1ï¼‰
2. **é˜¶æ®µ2ï¼šç»†ç²’åº¦åˆ†å¸ƒæœç´¢**ï¼ˆæ­¥é•¿=0.1ï¼‰

#### ä¸‰é˜¶æ®µæœç´¢ï¼ˆå¯ç”¨ `--search_freeze_layers`ï¼‰
1. **é˜¶æ®µ1ï¼šç²—ç²’åº¦åˆ†å¸ƒæœç´¢**ï¼ˆæ­¥é•¿=1ï¼‰
2. **é˜¶æ®µ2ï¼šç»†ç²’åº¦åˆ†å¸ƒæœç´¢**ï¼ˆæ­¥é•¿=0.1ï¼‰
3. **é˜¶æ®µ3ï¼šå†»ç»“å±‚æ•°æœç´¢**ï¼ˆåœ¨æœ€ä¼˜åˆ†å¸ƒä¸‹è´ªå¿ƒæœç´¢ï¼‰

### æ ¸å¿ƒç‰¹æ€§

1. **æ™ºèƒ½åŒå‘æœç´¢**
   - ä»æ™ºèƒ½èµ·ç‚¹å¼€å§‹ï¼ˆé»˜è®¤2:8ï¼ŒåŸºäºLLaMA-3å®é™…Attention:MLPå‚æ•°æ¯”ä¾‹ï¼‰
   - å‘ä¸¤è¾¹åŒæ—¶æœç´¢ï¼Œé¿å…ç›²ç›®æµ‹è¯•æ‰€æœ‰æ¯”ä¾‹

2. **æ™ºèƒ½æ—©åœæœºåˆ¶**
   - æ£€æµ‹æ¡ä»¶ï¼šè¿ç»­2-3æ¬¡PPLå¢å¤§ä¸”å¢é€ŸåŠ å¿«ï¼ˆäºŒé˜¶å¯¼æ•°ä¸ºæ­£ï¼‰
   - è‡ªåŠ¨åœæ­¢æ— ä»·å€¼çš„æœç´¢æ–¹å‘
   - åŸºäºå®é™…è§‚å¯Ÿï¼šPPLå¾€å¾€åœ¨æŸä¸ªæ–¹å‘ä¸Šå•è°ƒé€’å¢

3. **ä¸¤é˜¶æ®µè´ªå¿ƒï¼ˆå†»ç»“å±‚ä¼˜åŒ–ï¼‰**
   - å…ˆå›ºå®šfreeze=0ï¼Œæœç´¢æœ€ä¼˜åˆ†å¸ƒ
   - åœ¨æœ€ä¼˜åˆ†å¸ƒä¸‹ï¼Œæœç´¢æœ€ä¼˜å†»ç»“å±‚æ•°
   - é¿å…exhaustive grid searchï¼ˆåˆ†å¸ƒÃ—å†»ç»“å±‚=120+æ¬¡æµ‹è¯•ï¼‰
   - ä¸¤é˜¶æ®µè´ªå¿ƒï¼š~23æ¬¡æµ‹è¯•å³å¯å®Œæˆ

4. **æœç´¢æ•ˆç‡**
   - ç²—ç²’åº¦ï¼šä»11æ¬¡å‡å°‘åˆ°5-9æ¬¡ï¼ˆèŠ‚çœ20-50%ï¼‰
   - ç»†ç²’åº¦ï¼šè‡ªåŠ¨åœæ­¢è¿œç¦»æœ€ä¼˜ç‚¹çš„æµ‹è¯•
   - å†»ç»“å±‚æœç´¢ï¼š8ä¸ªå€™é€‰å€¼ï¼Œé€šå¸¸æµ‹è¯•4-6ä¸ªï¼ˆæ—©åœï¼‰
   - æ€»ä½“ï¼šé¢„è®¡èŠ‚çœ30-40%æ—¶é—´

### å·¥ä½œåŸç†

**é˜¶æ®µ1ï¼šç²—ç²’åº¦æœç´¢**ï¼ˆåŸºäºæ‚¨çš„æ•°æ®ï¼‰ï¼š
```
èµ·ç‚¹: 2:8 (æ™ºèƒ½èµ·ç‚¹ï¼ŒåŸºäºLLaMA-3å®é™…å‚æ•°æ¯”ä¾‹ 19.2%:80.8%)
å‘å·¦: 1:9 (PPL = 73.59) â†’ 0:10 (PPL = 46.87) âœ…æœ€ä¼˜
å‘å³: 3:7 (PPL = 137.70) â†’ 4:6 (PPLæ›´é«˜ï¼ŒåŠ é€Ÿå¢å¤§ï¼Œæ—©åœï¼)
      [è·³è¿‡ 5:5, 6:4, 7:3, 8:2, 9:1, 10:0]
èŠ‚çœ: 6æ¬¡æµ‹è¯•ï¼ˆ55%ï¼‰
```

**é˜¶æ®µ2ï¼šç»†ç²’åº¦æœç´¢**ï¼ˆä»0:10å¼€å§‹ï¼‰ï¼š
```
ä¸­å¿ƒ: 0:10 (PPL = 46.87)
å‘å·¦: (Attentionå·²ä¸º0ï¼Œæ— æ³•ç»§ç»­)
å‘å³: 0.1:9.9 â†’ 0.2:9.8 â†’ 0.3:9.7 (PPL = 45.12) âœ…æœ€ä¼˜
      0.4:9.6 â†’ 0.5:9.5 â†’ 0.6:9.4 (PPLåŠ é€Ÿå¢å¤§ï¼Œæ—©åœï¼)
      [è·³è¿‡ 0.7:9.3, 0.8:9.2, 0.9:9.1, 1.0:9.0]
èŠ‚çœ: 4æ¬¡æµ‹è¯•ï¼ˆ40%ï¼‰
```

**é˜¶æ®µ3ï¼šå†»ç»“å±‚æ•°æœç´¢**ï¼ˆå¯é€‰ï¼Œåœ¨æœ€ä¼˜åˆ†å¸ƒ0.3:9.7ä¸‹ï¼‰ï¼š
```
æœç´¢èŒƒå›´: [0, 1, 2, 3, 4, 5, 6, 8]
freeze=0: PPL = 45.12 (åŸºå‡†)
freeze=1: PPL = 44.98 âœ…
freeze=2: PPL = 44.85 âœ…æœ€ä¼˜
freeze=3: PPL = 45.01
freeze=4: PPL = 45.23 (è¿ç»­å¢å¤§ï¼Œæ—©åœï¼)
      [è·³è¿‡ freeze=5, 6, 8]
èŠ‚çœ: 3æ¬¡æµ‹è¯•ï¼ˆ38%ï¼‰
æœ€ä¼˜é…ç½®: 0.3:9.7 + freeze=2
```

---

## å¿«é€Ÿå¼€å§‹

### åŸºæœ¬ä½¿ç”¨

```bash
# æœ€ç®€å•çš„ç”¨æ³•ï¼ˆä½¿ç”¨æ‰€æœ‰é»˜è®¤å‚æ•°ï¼‰
python search_optimal_distribution.py \
    --base_model /newdata/LLMs/Llama-3-8B-Instruct
```

è¿™å°†ï¼š
1. æµ‹è¯• 11 ä¸ªç²—ç²’åº¦æ¯”ä¾‹ï¼ˆ0:10, 1:9, ..., 10:0ï¼‰
2. æ‰¾åˆ°æœ€ä¼˜çš„ä¸¤ä¸ªç›¸é‚»æ¯”ä¾‹
3. åœ¨å®ƒä»¬ä¹‹é—´è¿›è¡Œç»†ç²’åº¦æœç´¢ï¼ˆæ­¥é•¿0.1ï¼‰
4. è¾“å‡ºå…¨å±€æœ€ä¼˜æ¯”ä¾‹å’Œå¯¹åº”PPL

---

## é«˜çº§ç”¨æ³•

### 1. æŒ‡å®šå‰ªæç‡

```bash
# æµ‹è¯•30%å‰ªæç‡
python search_optimal_distribution.py \
    --base_model /newdata/LLMs/Llama-3-8B-Instruct \
    --pruning_ratio 0.30
```

### 2. ä¸‰é˜¶æ®µæœç´¢ï¼ˆåˆ†å¸ƒ+å†»ç»“å±‚ä¼˜åŒ–ï¼‰

```bash
# è‡ªåŠ¨æœç´¢æœ€ä¼˜å†»ç»“å±‚æ•°
python search_optimal_distribution.py \
    --base_model /newdata/LLMs/Llama-3-8B-Instruct \
    --pruning_ratio 0.25 \
    --search_freeze_layers \
    --freeze_range 0,1,2,3,4,5,6,8
```

**è¯´æ˜**ï¼š
- å…ˆæœç´¢æœ€ä¼˜åˆ†å¸ƒï¼ˆé˜¶æ®µ1+2ï¼‰
- åœ¨æœ€ä¼˜åˆ†å¸ƒä¸‹æœç´¢æœ€ä¼˜å†»ç»“å±‚æ•°ï¼ˆé˜¶æ®µ3ï¼‰
- é»˜è®¤æœç´¢èŒƒå›´ï¼š[0, 1, 2, 3, 4, 5, 6, 8]
- ä½¿ç”¨æ—©åœæœºåˆ¶ï¼Œé€šå¸¸æµ‹è¯•4-6ä¸ªå€¼å³å¯

### 3. å›ºå®šå†»ç»“å±‚æ•°æœç´¢

```bash
# å›ºå®šå†»ç»“3å±‚ï¼Œä»…æœç´¢åˆ†å¸ƒ
python search_optimal_distribution.py \
    --base_model /newdata/LLMs/Llama-3-8B-Instruct \
    --pruning_ratio 0.25 \
    --freeze_top_n_layers 3
```

**æ¨èå†»ç»“å±‚æ•°**ï¼š
- å°æ¨¡å‹ï¼ˆ7-13Bï¼‰ï¼š3-5 å±‚
- å¤§æ¨¡å‹ï¼ˆ30B+ï¼‰ï¼š5-10 å±‚

### 4. è‡ªå®šä¹‰æœç´¢èµ·ç‚¹

```bash
# ä½¿ç”¨è‡ªå®šä¹‰èµ·ç‚¹ï¼ˆä¾‹å¦‚åŸºäºæ¨¡å‹å®é™…å‚æ•°æ¯”ä¾‹ï¼‰
python search_optimal_distribution.py \
    --base_model /newdata/LLMs/Llama-3-8B-Instruct \
    --pruning_ratio 0.25 \
    --coarse_start_ratio 3:7
```

**è¯´æ˜**ï¼š
- é»˜è®¤èµ·ç‚¹ï¼š2:8ï¼ˆåŸºäºLLaMA-3çš„Attention:MLPå‚æ•°æ¯”ä¾‹ï¼‰
- å¯æ ¹æ®å…·ä½“æ¨¡å‹æ¶æ„è°ƒæ•´èµ·ç‚¹
- æ›´æ¥è¿‘æœ€ä¼˜ç‚¹çš„èµ·ç‚¹å¯ä»¥è¿›ä¸€æ­¥æå‡æœç´¢æ•ˆç‡

### 5. å®Œæ•´é…ç½®ç¤ºä¾‹

```bash
# ä¸‰é˜¶æ®µæœç´¢ + å®Œæ•´é…ç½®
python search_optimal_distribution.py \
    --base_model /newdata/LLMs/Llama-3-8B-Instruct \
    --pruning_ratio 0.25 \
    --save_ckpt_log_name my_ppl_search_20250117 \
    --search_freeze_layers \
    --freeze_range 0,1,2,3,4,5,6,8 \
    --coarse_start_ratio 2:8 \
    --layer_importance_method removal \
    --pruning_strategy inverse
```

### 6. åŠ é€Ÿæµ‹è¯•ï¼ˆå‡å°‘æ ·æœ¬æ•°ï¼‰

```bash
# å¿«é€Ÿæµ‹è¯•ï¼ˆç”¨äºéªŒè¯æµç¨‹ï¼‰
python search_optimal_distribution.py \
    --base_model /newdata/LLMs/Llama-3-8B-Instruct \
    --pruning_ratio 0.25 \
    --layer_importance_samples 20 \
    --channel_importance_samples 5
```

âš ï¸ **æ³¨æ„**ï¼šå‡å°‘æ ·æœ¬æ•°ä¼šåŠ å¿«é€Ÿåº¦ï¼Œä½†å¯èƒ½å½±å“ç»“æœå‡†ç¡®æ€§ã€‚å»ºè®®å…ˆå¿«é€Ÿæµ‹è¯•ï¼Œç¡®è®¤æµç¨‹æ­£å¸¸åå†ç”¨å®Œæ•´å‚æ•°ã€‚

---

## è¾“å‡ºè§£è¯»

### ç»ˆç«¯è¾“å‡ºç¤ºä¾‹

```
============================================================
å¼€å§‹PPLä¼˜åŒ–æœç´¢
============================================================
åŸºç¡€æ¨¡å‹: /newdata/LLMs/Llama-3-8B-Instruct
æ€»å‰ªæç‡: 25.00%
é¢å¤–å‚æ•°: --freeze_top_n_layers 3

============================================================
é˜¶æ®µ1: ç²—ç²’åº¦æœç´¢ (æ­¥é•¿=1)
============================================================

============================================================
å¼€å§‹å®éªŒ: Attention:MLP = 0.0:10.0
============================================================
æ‰§è¡Œå‘½ä»¤: python llama3_unbalanced_pruning_gqa_aware.py ...
âœ… å®éªŒå®Œæˆ: 0.0:10.0 -> PPL = 46.87

============================================================
å¼€å§‹å®éªŒ: Attention:MLP = 1.0:9.0
============================================================
æ‰§è¡Œå‘½ä»¤: python llama3_unbalanced_pruning_gqa_aware.py ...
âœ… å®éªŒå®Œæˆ: 1.0:9.0 -> PPL = 73.59

[... ç»§ç»­æµ‹è¯•å…¶ä»–æ¯”ä¾‹ ...]

ç²—ç²’åº¦æœç´¢ç»“æœï¼ˆæŒ‰PPLå‡åºï¼‰:
  1. 0.0:10.0 -> PPL = 46.87
  2. 1.0:9.0 -> PPL = 73.59
  3. 2.0:8.0 -> PPL = 83.77
  4. 3.0:7.0 -> PPL = 137.70
  5. 5.0:5.0 -> PPL = 142.35

âœ… ç²—ç²’åº¦æœç´¢æœ€ä½³: 0.0:10.0 (PPL = 46.87)
é€‰æ‹©ç›¸é‚»æ¯”ä¾‹: 1.0:9.0

============================================================
é˜¶æ®µ2: ç»†ç²’åº¦æœç´¢ (æ­¥é•¿=0.1)
æœç´¢åŒºé—´: 0.0:10.0 åˆ° 1.0:9.0
============================================================

[æµ‹è¯• 0.1:9.9, 0.2:9.8, 0.3:9.7, ..., 0.9:9.1]

âœ… å®éªŒå®Œæˆ: 0.1:9.9 -> PPL = 46.23
âœ… å®éªŒå®Œæˆ: 0.2:9.8 -> PPL = 45.89
âœ… å®éªŒå®Œæˆ: 0.3:9.7 -> PPL = 45.12
âœ… å®éªŒå®Œæˆ: 0.4:9.6 -> PPL = 47.23
...

============================================================
ç»†ç²’åº¦æœç´¢å®Œæˆ
============================================================
âœ… å…¨å±€æœ€ä¼˜: 0.3:9.7 (PPL = 45.12)

============================================================
æœç´¢å®Œæˆ
============================================================
æ€»è€—æ—¶: 4:32:15
æµ‹è¯•æ¬¡æ•°: 20
æœ€ä¼˜æ¯”ä¾‹: 0.3:9.7
æœ€ä¼˜PPL: 45.12
ç»“æœå·²ä¿å­˜åˆ°: prune_log/my_ppl_search/search_results.json

æ‰€æœ‰æµ‹è¯•ç»“æœï¼ˆæŒ‰PPLå‡åºï¼‰:
  ğŸ†  1. 0.3:9.7 -> PPL =   45.12
      2. 0.2:9.8 -> PPL =   45.89
      3. 0.1:9.9 -> PPL =   46.23
      4. 0.0:10.0 -> PPL =   46.87
      5. 0.4:9.6 -> PPL =   47.23
      6. 0.5:9.5 -> PPL =   52.34
      7. 0.6:9.4 -> PPL =   58.91
      8. 0.7:9.3 -> PPL =   65.12
      9. 0.8:9.2 -> PPL =   69.45
     10. 0.9:9.1 -> PPL =   71.23
     11. 1.0:9.0 -> PPL =   73.59
     12. 2.0:8.0 -> PPL =   83.77
     13. 3.0:7.0 -> PPL =  137.70
     [...]

ğŸ‰ æœç´¢æˆåŠŸï¼
æœ€ä¼˜ Attention:MLP æ¯”ä¾‹: 0.3:9.7
å¯¹åº”çš„ PPL: 45.12

å¯ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤è¿›è¡Œæœ€ä¼˜æ¯”ä¾‹å‰ªæ:
python llama3_unbalanced_pruning_gqa_aware.py \
    --base_model /newdata/LLMs/Llama-3-8B-Instruct \
    --pruning_distribution 0.3:9.7 \
    --pruning_ratio 0.25 \
    --freeze_top_n_layers 3 \
    --save_model --test_after_prune
```

### è¾“å‡ºæ–‡ä»¶

æœç´¢å®Œæˆåï¼Œç»“æœä¿å­˜åœ¨ `prune_log/<experiment_name>/` ç›®å½•ä¸‹ï¼š

```
prune_log/my_ppl_search/
â”œâ”€â”€ search_results.json          # æ‰€æœ‰æµ‹è¯•ç»“æœï¼ˆJSONæ ¼å¼ï¼‰
â”œâ”€â”€ search.log                   # è¯¦ç»†æœç´¢æ—¥å¿—
â”œâ”€â”€ ratio_0_0_10_0/              # æ¯ä¸ªæ¯”ä¾‹çš„å‰ªææ—¥å¿—
â”‚   â””â”€â”€ <timestamp>/
â”‚       â””â”€â”€ training.log
â”œâ”€â”€ ratio_0_1_9_9/
â”œâ”€â”€ ratio_0_2_9_8/
â””â”€â”€ ...
```

**search_results.json ç¤ºä¾‹**ï¼š

```json
{
  "timestamp": "2025-01-17T15:30:45.123456",
  "base_model": "/newdata/LLMs/Llama-3-8B-Instruct",
  "pruning_ratio": 0.25,
  "results": {
    "0.0:10.0": 46.87,
    "1.0:9.0": 73.59,
    "2.0:8.0": 83.77,
    "0.3:9.7": 45.12,
    "0.2:9.8": 45.89,
    ...
  },
  "best_ratio": "0.3:9.7",
  "best_ppl": 45.12
}
```

---

## å®æˆ˜æ¡ˆä¾‹

### æ¡ˆä¾‹1ï¼šåŸºäºæ‚¨çš„å®éªŒæ•°æ®

æ ¹æ®æ‚¨æä¾›çš„å®éªŒç»“æœï¼š
- 0:10 â†’ PPL = 46.87
- 1:9 â†’ PPL = 73.59
- 2:8 â†’ PPL = 83.77
- 3:7 â†’ PPL = 137.70

æœ€ä¼˜åŒºé—´åœ¨ **0:10 åˆ° 1:9** ä¹‹é—´ã€‚ä½¿ç”¨æœç´¢è„šæœ¬ä¼šè‡ªåŠ¨åœ¨è¿™ä¸ªåŒºé—´ç»†åŒ–æœç´¢ï¼š

```bash
python search_optimal_distribution.py \
    --base_model /newdata/LLMs/Llama-3-8B-Instruct \
    --pruning_ratio 0.25
```

é¢„æœŸä¼šæ‰¾åˆ°ç±»ä¼¼ **0.3:9.7** æˆ– **0.5:9.5** çš„æœ€ä¼˜æ¯”ä¾‹ã€‚

### æ¡ˆä¾‹2ï¼šä¸åŒå‰ªæç‡å¯¹æ¯”

```bash
# æµ‹è¯• 20% å‰ªæç‡çš„æœ€ä¼˜æ¯”ä¾‹
python search_optimal_distribution.py \
    --base_model /newdata/LLMs/Llama-3-8B-Instruct \
    --pruning_ratio 0.20 \
    --save_ckpt_log_name search_20pct

# æµ‹è¯• 30% å‰ªæç‡çš„æœ€ä¼˜æ¯”ä¾‹
python search_optimal_distribution.py \
    --base_model /newdata/LLMs/Llama-3-8B-Instruct \
    --pruning_ratio 0.30 \
    --save_ckpt_log_name search_30pct
```

å¯¹æ¯”ä¸¤ä¸ªå‰ªæç‡çš„æœ€ä¼˜åˆ†å¸ƒï¼Œåˆ†æè¶‹åŠ¿ã€‚

### æ¡ˆä¾‹3ï¼šè‡ªåŠ¨æœç´¢æœ€ä¼˜å†»ç»“å±‚æ•°

```bash
# ä¸‰é˜¶æ®µæœç´¢ï¼šè‡ªåŠ¨æ‰¾åˆ°æœ€ä¼˜åˆ†å¸ƒå’Œå†»ç»“å±‚æ•°
python search_optimal_distribution.py \
    --base_model /newdata/LLMs/Llama-3-8B-Instruct \
    --pruning_ratio 0.25 \
    --search_freeze_layers \
    --freeze_range 0,1,2,3,4,5,6,8 \
    --save_ckpt_log_name search_optimal_freeze
```

**é¢„æœŸç»“æœ**ï¼š
- é˜¶æ®µ1+2ï¼šæ‰¾åˆ°æœ€ä¼˜åˆ†å¸ƒï¼ˆä¾‹å¦‚ 0.3:9.7ï¼‰
- é˜¶æ®µ3ï¼šåœ¨è¯¥åˆ†å¸ƒä¸‹æ‰¾åˆ°æœ€ä¼˜å†»ç»“å±‚æ•°ï¼ˆä¾‹å¦‚ freeze=2ï¼‰
- æœ€ç»ˆè¾“å‡ºå®Œæ•´çš„æœ€ä¼˜é…ç½®å‘½ä»¤

### æ¡ˆä¾‹4ï¼šå±‚å†»ç»“å¯¹æ¯”å®éªŒï¼ˆå›ºå®šå†»ç»“å±‚ï¼‰

```bash
# ä¸å†»ç»“å±‚
python search_optimal_distribution.py \
    --base_model /newdata/LLMs/Llama-3-8B-Instruct \
    --save_ckpt_log_name search_no_freeze

# å†»ç»“3å±‚
python search_optimal_distribution.py \
    --base_model /newdata/LLMs/Llama-3-8B-Instruct \
    --freeze_top_n_layers 3 \
    --save_ckpt_log_name search_freeze_3

# å†»ç»“5å±‚
python search_optimal_distribution.py \
    --base_model /newdata/LLMs/Llama-3-8B-Instruct \
    --freeze_top_n_layers 5 \
    --save_ckpt_log_name search_freeze_5
```

å¯¹æ¯”å†»ç»“ä¸åŒå±‚æ•°çš„æœ€ä¼˜PPLï¼Œè¯„ä¼°å±‚å†»ç»“çš„æ•ˆæœã€‚

---

## æœ€ä½³å®è·µ

### 1. éªŒè¯æµç¨‹

åœ¨æ­£å¼è¿è¡Œé•¿æ—¶é—´æœç´¢å‰ï¼Œå…ˆå¿«é€ŸéªŒè¯ï¼š

```bash
# å¿«é€ŸéªŒè¯ï¼ˆä»…æµ‹è¯• 0:10 å’Œ 10:0ï¼‰
python llama3_unbalanced_pruning_gqa_aware.py \
    --base_model /newdata/LLMs/Llama-3-8B-Instruct \
    --pruning_distribution 0:10 \
    --layer_importance_samples 10 \
    --channel_importance_samples 5 \
    --test_after_prune

python llama3_unbalanced_pruning_gqa_aware.py \
    --base_model /newdata/LLMs/Llama-3-8B-Instruct \
    --pruning_distribution 10:0 \
    --layer_importance_samples 10 \
    --channel_importance_samples 5 \
    --test_after_prune
```

ç¡®è®¤æµç¨‹æ— è¯¯åå†è¿è¡Œå®Œæ•´æœç´¢ã€‚

### 2. åˆ†é˜¶æ®µæ‰§è¡Œ

å¦‚æœæ‹…å¿ƒå®Œæ•´æœç´¢æ—¶é—´è¿‡é•¿ï¼Œå¯ä»¥åˆ†é˜¶æ®µæ‰§è¡Œï¼š

```bash
# é˜¶æ®µ1ï¼šåªåšç²—ç²’åº¦æœç´¢ï¼ˆæ‰‹åŠ¨ï¼‰
for dist in 0:10 1:9 2:8 3:7 4:6 5:5 6:4 7:3 8:2 9:1 10:0; do
    python llama3_unbalanced_pruning_gqa_aware.py \
        --pruning_distribution $dist \
        --test_after_prune
done

# åˆ†æç»“æœï¼Œæ‰¾åˆ°æœ€ä¼˜åŒºé—´

# é˜¶æ®µ2ï¼šåœ¨æœ€ä¼˜åŒºé—´ç»†åŒ–æœç´¢
for i in {1..9}; do
    ratio=$(echo "scale=1; $i/10" | bc)
    ratio2=$(echo "scale=1; 10-$ratio" | bc)
    python llama3_unbalanced_pruning_gqa_aware.py \
        --pruning_distribution ${ratio}:${ratio2} \
        --test_after_prune
done
```

### 3. å¹¶è¡ŒåŠ é€Ÿ

å¦‚æœæœ‰å¤šä¸ªGPUï¼Œå¯ä»¥æ‰‹åŠ¨å¹¶è¡Œï¼š

```bash
# GPU 0: æµ‹è¯• 0:10 åˆ° 5:5
CUDA_VISIBLE_DEVICES=0 python search_optimal_distribution.py \
    --base_model /path/to/model \
    --save_ckpt_log_name search_gpu0 &

# GPU 1: æ‰‹åŠ¨æµ‹è¯•å…¶ä»–æ¯”ä¾‹
CUDA_VISIBLE_DEVICES=1 python llama3_unbalanced_pruning_gqa_aware.py \
    --pruning_distribution 6:4 \
    --test_after_prune &

# ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
wait
```

### 4. ç›‘æ§è¿›åº¦

æœç´¢è¿‡ç¨‹ä¸­å¯ä»¥å®æ—¶æŸ¥çœ‹è¿›åº¦ï¼š

```bash
# æŸ¥çœ‹å½“å‰æœç´¢æ—¥å¿—
tail -f prune_log/my_ppl_search/search.log

# æŸ¥çœ‹å·²å®Œæˆçš„ç»“æœ
cat prune_log/my_ppl_search/search_results.json | python -m json.tool
```

---

## æ•…éšœæ’é™¤

### é—®é¢˜1ï¼šæœç´¢å¡ä½ä¸åŠ¨

**ç—‡çŠ¶**ï¼šé•¿æ—¶é—´æ²¡æœ‰è¾“å‡º

**è§£å†³æ–¹æ³•**ï¼š
1. æ£€æŸ¥æ˜¯å¦æœ‰GPUèµ„æºè¢«å ç”¨
2. æŸ¥çœ‹å­è¿›ç¨‹æ—¥å¿—ï¼š`tail -f prune_log/<experiment_name>/ratio_*/*/training.log`
3. æ£€æŸ¥å†…å­˜æ˜¯å¦ä¸è¶³ï¼ˆOOMï¼‰

### é—®é¢˜2ï¼šPPLæå–å¤±è´¥

**ç—‡çŠ¶**ï¼šçœ‹åˆ° "âŒ æ— æ³•ä»è¾“å‡ºä¸­æå–PPL"

**è§£å†³æ–¹æ³•**ï¼š
1. æ£€æŸ¥å­å®éªŒçš„æ—¥å¿—ï¼ŒæŸ¥çœ‹æ˜¯å¦æˆåŠŸè¿è¡Œ
2. ç¡®è®¤ä½¿ç”¨äº† `--test_after_prune` å‚æ•°
3. æ‰‹åŠ¨è¿è¡Œä¸€æ¬¡å‰ªæè„šæœ¬ï¼Œç¡®è®¤PPLè¾“å‡ºæ ¼å¼

### é—®é¢˜3ï¼šä¸­é€”ä¸­æ–­åå¦‚ä½•æ¢å¤

**æ–¹æ³•**ï¼š
1. æŸ¥çœ‹ `search_results.json`ï¼Œç¡®è®¤å·²å®Œæˆçš„æ¯”ä¾‹
2. æ‰‹åŠ¨è¡¥å……æœªå®Œæˆçš„æ¯”ä¾‹æµ‹è¯•
3. åˆå¹¶ç»“æœåˆ°åŒä¸€ä¸ªJSONæ–‡ä»¶

---

## æ€§èƒ½ä¼˜åŒ–å»ºè®®

| ä¼˜åŒ–æ–¹æ³• | æ—¶é—´èŠ‚çœ | å‡†ç¡®æ€§å½±å“ |
|---------|---------|-----------|
| å‡å°‘ `layer_importance_samples` (50â†’20) | ~30% | å° |
| å‡å°‘ `channel_importance_samples` (10â†’5) | ~20% | å° |
| è·³è¿‡å±‚é‡è¦æ€§åˆ†æï¼ˆå¤ç”¨é…ç½®ï¼‰ | ~40% | æ— ï¼ˆéœ€å…ˆè¿è¡Œä¸€æ¬¡ï¼‰ |
| ä½¿ç”¨æ›´å¿«çš„GPUï¼ˆA100 vs V100ï¼‰ | ~50% | æ—  |
| å¤šGPUå¹¶è¡Œï¼ˆæ‰‹åŠ¨åˆ†é…ï¼‰ | ~2-4x | æ—  |

**æ¨èé…ç½®**ï¼ˆå¿«é€Ÿæµ‹è¯•ï¼‰ï¼š
```bash
python search_optimal_distribution.py \
    --base_model /path/to/model \
    --layer_importance_samples 20 \
    --channel_importance_samples 5
```

**æ¨èé…ç½®**ï¼ˆç”Ÿäº§ç¯å¢ƒï¼‰ï¼š
```bash
python search_optimal_distribution.py \
    --base_model /path/to/model \
    --layer_importance_samples 50 \
    --channel_importance_samples 10
```

---

## æ€»ç»“

è‡ªåŠ¨æœç´¢è„šæœ¬å¯ä»¥å¤§å¹…ç®€åŒ–æœ€ä¼˜å‰ªææ¯”ä¾‹çš„å¯»æ‰¾è¿‡ç¨‹ï¼š

âœ… **ä¼˜ç‚¹**ï¼š
- å…¨è‡ªåŠ¨åŒ–ï¼Œæ— éœ€äººå·¥å¹²é¢„
- ä¸¤é˜¶æ®µç­–ç•¥é«˜æ•ˆä¸”ç²¾ç¡®
- ç»“æœå¯å¤ç°ï¼Œä¿å­˜å®Œæ•´å†å²

âš ï¸ **æ³¨æ„**ï¼š
- å®Œæ•´æœç´¢éœ€è¦æ•°å°æ—¶
- å»ºè®®å…ˆéªŒè¯æµç¨‹å†è¿è¡Œ
- å¯ä»¥éšæ—¶ä¸­æ–­ï¼Œç»“æœå·²ä¿å­˜

ğŸ¯ **é€‚ç”¨åœºæ™¯**ï¼š
- æ–°æ¨¡å‹é¦–æ¬¡å‰ªæï¼Œä¸ç¡®å®šæœ€ä¼˜æ¯”ä¾‹
- å¯¹æ¯”ä¸åŒå‰ªæç‡æˆ–å±‚å†»ç»“é…ç½®
- éœ€è¦ç³»ç»Ÿæ€§æ¢ç´¢å‚æ•°ç©ºé—´

ç¥æ‚¨æ‰¾åˆ°æœ€ä¼˜çš„å‰ªæé…ç½®ï¼ğŸ‰
