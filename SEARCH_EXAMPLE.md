# è‡ªåŠ¨PPLä¼˜åŒ–æœç´¢ - ä½¿ç”¨ç¤ºä¾‹

æœ¬æ–‡æ¡£æä¾› `search_optimal_distribution.py` çš„è¯¦ç»†ä½¿ç”¨ç¤ºä¾‹å’Œæœ€ä½³å®è·µã€‚

## ç®—æ³•æ¦‚è¿°

æœ¬è„šæœ¬é‡‡ç”¨**æ™ºèƒ½åŒå‘æœç´¢ + æ—©åœ**ç­–ç•¥ï¼Œç›¸æ¯”ä¼ ç»Ÿçš„çº¿æ€§æœç´¢ï¼Œå¯èŠ‚çœ30-50%çš„æµ‹è¯•æ—¶é—´ã€‚

### æ ¸å¿ƒç‰¹æ€§

1. **æ™ºèƒ½åŒå‘æœç´¢**
   - ä»ä¸­å¿ƒç‚¹å¼€å§‹ï¼Œå‘ä¸¤è¾¹åŒæ—¶æœç´¢
   - é¿å…ç›²ç›®æµ‹è¯•æ‰€æœ‰æ¯”ä¾‹

2. **æ™ºèƒ½æ—©åœæœºåˆ¶**
   - æ£€æµ‹æ¡ä»¶ï¼šè¿ç»­2-3æ¬¡PPLå¢å¤§ä¸”å¢é€ŸåŠ å¿«ï¼ˆäºŒé˜¶å¯¼æ•°ä¸ºæ­£ï¼‰
   - è‡ªåŠ¨åœæ­¢æ— ä»·å€¼çš„æœç´¢æ–¹å‘
   - åŸºäºå®é™…è§‚å¯Ÿï¼šPPLå¾€å¾€åœ¨æŸä¸ªæ–¹å‘ä¸Šå•è°ƒé€’å¢

3. **æœç´¢æ•ˆç‡**
   - ç²—ç²’åº¦ï¼šä»11æ¬¡å‡å°‘åˆ°5-9æ¬¡ï¼ˆèŠ‚çœ20-50%ï¼‰
   - ç»†ç²’åº¦ï¼šè‡ªåŠ¨åœæ­¢è¿œç¦»æœ€ä¼˜ç‚¹çš„æµ‹è¯•
   - æ€»ä½“ï¼šé¢„è®¡èŠ‚çœ30-40%æ—¶é—´

### å·¥ä½œåŸç†

**ç²—ç²’åº¦æœç´¢**ï¼ˆæ‚¨çš„æ•°æ®ç¤ºä¾‹ï¼‰ï¼š
```
å¼€å§‹: 5:5 (PPLé«˜)
å‘å·¦: 4:6 â†’ 3:7 â†’ 2:8 â†’ 1:9 â†’ 0:10 (PPL = 46.87) âœ…æœ€ä¼˜
å‘å³: 6:4 â†’ 7:3 â†’ 8:2 (PPLæŒç»­å¢å¤§ä¸”åŠ é€Ÿï¼Œæ—©åœï¼)
      [è·³è¿‡ 9:1, 10:0]
èŠ‚çœ: 2æ¬¡æµ‹è¯•
```

**ç»†ç²’åº¦æœç´¢**ï¼ˆä»0:10å¼€å§‹ï¼‰ï¼š
```
å‘å·¦: (Attentionå·²ä¸º0ï¼Œæ— æ³•ç»§ç»­)
å‘å³: 0.1 â†’ 0.2 â†’ 0.3 (PPL = 45.12) âœ…æœ€ä¼˜
      0.4 â†’ 0.5 â†’ 0.6 (PPLåŠ é€Ÿå¢å¤§ï¼Œæ—©åœï¼)
      [è·³è¿‡ 0.7, 0.8, 0.9, 1.0]
èŠ‚çœ: 4æ¬¡æµ‹è¯•
```

---

## å¿«é€Ÿå¼€å§‹

### åŸºæœ¬ä½¿ç”¨

```bash
# æœ€ç®€å•çš„ç”¨æ³•ï¼ˆä½¿ç”¨æ‰€æœ‰é»˜è®¤å‚æ•°ï¼‰
python search_optimal_distribution.py \
    --base_model /newdata/LLMs/Llama-3-8B-Instruct
```

è¿™å°†ï¼š
1. æµ‹è¯• 11 ä¸ªç²—ç²’åº¦æ¯”ä¾‹ï¼ˆ0:10, 1:9, ..., 10:0ï¼‰
2. æ‰¾åˆ°æœ€ä¼˜çš„ä¸¤ä¸ªç›¸é‚»æ¯”ä¾‹
3. åœ¨å®ƒä»¬ä¹‹é—´è¿›è¡Œç»†ç²’åº¦æœç´¢ï¼ˆæ­¥é•¿0.1ï¼‰
4. è¾“å‡ºå…¨å±€æœ€ä¼˜æ¯”ä¾‹å’Œå¯¹åº”PPL

---

## é«˜çº§ç”¨æ³•

### 1. æŒ‡å®šå‰ªæç‡

```bash
# æµ‹è¯•30%å‰ªæç‡
python search_optimal_distribution.py \
    --base_model /newdata/LLMs/Llama-3-8B-Instruct \
    --pruning_ratio 0.30
```

### 2. å¯ç”¨å±‚å†»ç»“

```bash
# ä¿æŠ¤æœ€é‡è¦çš„3å±‚
python search_optimal_distribution.py \
    --base_model /newdata/LLMs/Llama-3-8B-Instruct \
    --pruning_ratio 0.25 \
    --freeze_top_n_layers 3
```

**æ¨èå†»ç»“å±‚æ•°**ï¼š
- å°æ¨¡å‹ï¼ˆ7-13Bï¼‰ï¼š3-5 å±‚
- å¤§æ¨¡å‹ï¼ˆ30B+ï¼‰ï¼š5-10 å±‚

### 3. è‡ªå®šä¹‰æœç´¢é…ç½®

```bash
# å®Œæ•´é…ç½®ç¤ºä¾‹
python search_optimal_distribution.py \
    --base_model /newdata/LLMs/Llama-3-8B-Instruct \
    --pruning_ratio 0.25 \
    --save_ckpt_log_name my_ppl_search_20250117 \
    --freeze_top_n_layers 3 \
    --layer_importance_method removal \
    --pruning_strategy inverse
```

### 4. åŠ é€Ÿæµ‹è¯•ï¼ˆå‡å°‘æ ·æœ¬æ•°ï¼‰

```bash
# å¿«é€Ÿæµ‹è¯•ï¼ˆç”¨äºéªŒè¯æµç¨‹ï¼‰
python search_optimal_distribution.py \
    --base_model /newdata/LLMs/Llama-3-8B-Instruct \
    --pruning_ratio 0.25 \
    --layer_importance_samples 20 \
    --channel_importance_samples 5
```

âš ï¸ **æ³¨æ„**ï¼šå‡å°‘æ ·æœ¬æ•°ä¼šåŠ å¿«é€Ÿåº¦ï¼Œä½†å¯èƒ½å½±å“ç»“æœå‡†ç¡®æ€§ã€‚å»ºè®®å…ˆå¿«é€Ÿæµ‹è¯•ï¼Œç¡®è®¤æµç¨‹æ­£å¸¸åå†ç”¨å®Œæ•´å‚æ•°ã€‚

---

## è¾“å‡ºè§£è¯»

### ç»ˆç«¯è¾“å‡ºç¤ºä¾‹

```
============================================================
å¼€å§‹PPLä¼˜åŒ–æœç´¢
============================================================
åŸºç¡€æ¨¡å‹: /newdata/LLMs/Llama-3-8B-Instruct
æ€»å‰ªæç‡: 25.00%
é¢å¤–å‚æ•°: --freeze_top_n_layers 3

============================================================
é˜¶æ®µ1: ç²—ç²’åº¦æœç´¢ (æ­¥é•¿=1)
============================================================

============================================================
å¼€å§‹å®éªŒ: Attention:MLP = 0.0:10.0
============================================================
æ‰§è¡Œå‘½ä»¤: python llama3_unbalanced_pruning_gqa_aware.py ...
âœ… å®éªŒå®Œæˆ: 0.0:10.0 -> PPL = 46.87

============================================================
å¼€å§‹å®éªŒ: Attention:MLP = 1.0:9.0
============================================================
æ‰§è¡Œå‘½ä»¤: python llama3_unbalanced_pruning_gqa_aware.py ...
âœ… å®éªŒå®Œæˆ: 1.0:9.0 -> PPL = 73.59

[... ç»§ç»­æµ‹è¯•å…¶ä»–æ¯”ä¾‹ ...]

ç²—ç²’åº¦æœç´¢ç»“æœï¼ˆæŒ‰PPLå‡åºï¼‰:
  1. 0.0:10.0 -> PPL = 46.87
  2. 1.0:9.0 -> PPL = 73.59
  3. 2.0:8.0 -> PPL = 83.77
  4. 3.0:7.0 -> PPL = 137.70
  5. 5.0:5.0 -> PPL = 142.35

âœ… ç²—ç²’åº¦æœç´¢æœ€ä½³: 0.0:10.0 (PPL = 46.87)
é€‰æ‹©ç›¸é‚»æ¯”ä¾‹: 1.0:9.0

============================================================
é˜¶æ®µ2: ç»†ç²’åº¦æœç´¢ (æ­¥é•¿=0.1)
æœç´¢åŒºé—´: 0.0:10.0 åˆ° 1.0:9.0
============================================================

[æµ‹è¯• 0.1:9.9, 0.2:9.8, 0.3:9.7, ..., 0.9:9.1]

âœ… å®éªŒå®Œæˆ: 0.1:9.9 -> PPL = 46.23
âœ… å®éªŒå®Œæˆ: 0.2:9.8 -> PPL = 45.89
âœ… å®éªŒå®Œæˆ: 0.3:9.7 -> PPL = 45.12
âœ… å®éªŒå®Œæˆ: 0.4:9.6 -> PPL = 47.23
...

============================================================
ç»†ç²’åº¦æœç´¢å®Œæˆ
============================================================
âœ… å…¨å±€æœ€ä¼˜: 0.3:9.7 (PPL = 45.12)

============================================================
æœç´¢å®Œæˆ
============================================================
æ€»è€—æ—¶: 4:32:15
æµ‹è¯•æ¬¡æ•°: 20
æœ€ä¼˜æ¯”ä¾‹: 0.3:9.7
æœ€ä¼˜PPL: 45.12
ç»“æœå·²ä¿å­˜åˆ°: prune_log/my_ppl_search/search_results.json

æ‰€æœ‰æµ‹è¯•ç»“æœï¼ˆæŒ‰PPLå‡åºï¼‰:
  ğŸ†  1. 0.3:9.7 -> PPL =   45.12
      2. 0.2:9.8 -> PPL =   45.89
      3. 0.1:9.9 -> PPL =   46.23
      4. 0.0:10.0 -> PPL =   46.87
      5. 0.4:9.6 -> PPL =   47.23
      6. 0.5:9.5 -> PPL =   52.34
      7. 0.6:9.4 -> PPL =   58.91
      8. 0.7:9.3 -> PPL =   65.12
      9. 0.8:9.2 -> PPL =   69.45
     10. 0.9:9.1 -> PPL =   71.23
     11. 1.0:9.0 -> PPL =   73.59
     12. 2.0:8.0 -> PPL =   83.77
     13. 3.0:7.0 -> PPL =  137.70
     [...]

ğŸ‰ æœç´¢æˆåŠŸï¼
æœ€ä¼˜ Attention:MLP æ¯”ä¾‹: 0.3:9.7
å¯¹åº”çš„ PPL: 45.12

å¯ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤è¿›è¡Œæœ€ä¼˜æ¯”ä¾‹å‰ªæ:
python llama3_unbalanced_pruning_gqa_aware.py \
    --base_model /newdata/LLMs/Llama-3-8B-Instruct \
    --pruning_distribution 0.3:9.7 \
    --pruning_ratio 0.25 \
    --freeze_top_n_layers 3 \
    --save_model --test_after_prune
```

### è¾“å‡ºæ–‡ä»¶

æœç´¢å®Œæˆåï¼Œç»“æœä¿å­˜åœ¨ `prune_log/<experiment_name>/` ç›®å½•ä¸‹ï¼š

```
prune_log/my_ppl_search/
â”œâ”€â”€ search_results.json          # æ‰€æœ‰æµ‹è¯•ç»“æœï¼ˆJSONæ ¼å¼ï¼‰
â”œâ”€â”€ search.log                   # è¯¦ç»†æœç´¢æ—¥å¿—
â”œâ”€â”€ ratio_0_0_10_0/              # æ¯ä¸ªæ¯”ä¾‹çš„å‰ªææ—¥å¿—
â”‚   â””â”€â”€ <timestamp>/
â”‚       â””â”€â”€ training.log
â”œâ”€â”€ ratio_0_1_9_9/
â”œâ”€â”€ ratio_0_2_9_8/
â””â”€â”€ ...
```

**search_results.json ç¤ºä¾‹**ï¼š

```json
{
  "timestamp": "2025-01-17T15:30:45.123456",
  "base_model": "/newdata/LLMs/Llama-3-8B-Instruct",
  "pruning_ratio": 0.25,
  "results": {
    "0.0:10.0": 46.87,
    "1.0:9.0": 73.59,
    "2.0:8.0": 83.77,
    "0.3:9.7": 45.12,
    "0.2:9.8": 45.89,
    ...
  },
  "best_ratio": "0.3:9.7",
  "best_ppl": 45.12
}
```

---

## å®æˆ˜æ¡ˆä¾‹

### æ¡ˆä¾‹1ï¼šåŸºäºæ‚¨çš„å®éªŒæ•°æ®

æ ¹æ®æ‚¨æä¾›çš„å®éªŒç»“æœï¼š
- 0:10 â†’ PPL = 46.87
- 1:9 â†’ PPL = 73.59
- 2:8 â†’ PPL = 83.77
- 3:7 â†’ PPL = 137.70

æœ€ä¼˜åŒºé—´åœ¨ **0:10 åˆ° 1:9** ä¹‹é—´ã€‚ä½¿ç”¨æœç´¢è„šæœ¬ä¼šè‡ªåŠ¨åœ¨è¿™ä¸ªåŒºé—´ç»†åŒ–æœç´¢ï¼š

```bash
python search_optimal_distribution.py \
    --base_model /newdata/LLMs/Llama-3-8B-Instruct \
    --pruning_ratio 0.25
```

é¢„æœŸä¼šæ‰¾åˆ°ç±»ä¼¼ **0.3:9.7** æˆ– **0.5:9.5** çš„æœ€ä¼˜æ¯”ä¾‹ã€‚

### æ¡ˆä¾‹2ï¼šä¸åŒå‰ªæç‡å¯¹æ¯”

```bash
# æµ‹è¯• 20% å‰ªæç‡çš„æœ€ä¼˜æ¯”ä¾‹
python search_optimal_distribution.py \
    --base_model /newdata/LLMs/Llama-3-8B-Instruct \
    --pruning_ratio 0.20 \
    --save_ckpt_log_name search_20pct

# æµ‹è¯• 30% å‰ªæç‡çš„æœ€ä¼˜æ¯”ä¾‹
python search_optimal_distribution.py \
    --base_model /newdata/LLMs/Llama-3-8B-Instruct \
    --pruning_ratio 0.30 \
    --save_ckpt_log_name search_30pct
```

å¯¹æ¯”ä¸¤ä¸ªå‰ªæç‡çš„æœ€ä¼˜åˆ†å¸ƒï¼Œåˆ†æè¶‹åŠ¿ã€‚

### æ¡ˆä¾‹3ï¼šå±‚å†»ç»“å¯¹æ¯”å®éªŒ

```bash
# ä¸å†»ç»“å±‚
python search_optimal_distribution.py \
    --base_model /newdata/LLMs/Llama-3-8B-Instruct \
    --save_ckpt_log_name search_no_freeze

# å†»ç»“3å±‚
python search_optimal_distribution.py \
    --base_model /newdata/LLMs/Llama-3-8B-Instruct \
    --freeze_top_n_layers 3 \
    --save_ckpt_log_name search_freeze_3

# å†»ç»“5å±‚
python search_optimal_distribution.py \
    --base_model /newdata/LLMs/Llama-3-8B-Instruct \
    --freeze_top_n_layers 5 \
    --save_ckpt_log_name search_freeze_5
```

å¯¹æ¯”å†»ç»“ä¸åŒå±‚æ•°çš„æœ€ä¼˜PPLï¼Œè¯„ä¼°å±‚å†»ç»“çš„æ•ˆæœã€‚

---

## æœ€ä½³å®è·µ

### 1. éªŒè¯æµç¨‹

åœ¨æ­£å¼è¿è¡Œé•¿æ—¶é—´æœç´¢å‰ï¼Œå…ˆå¿«é€ŸéªŒè¯ï¼š

```bash
# å¿«é€ŸéªŒè¯ï¼ˆä»…æµ‹è¯• 0:10 å’Œ 10:0ï¼‰
python llama3_unbalanced_pruning_gqa_aware.py \
    --base_model /newdata/LLMs/Llama-3-8B-Instruct \
    --pruning_distribution 0:10 \
    --layer_importance_samples 10 \
    --channel_importance_samples 5 \
    --test_after_prune

python llama3_unbalanced_pruning_gqa_aware.py \
    --base_model /newdata/LLMs/Llama-3-8B-Instruct \
    --pruning_distribution 10:0 \
    --layer_importance_samples 10 \
    --channel_importance_samples 5 \
    --test_after_prune
```

ç¡®è®¤æµç¨‹æ— è¯¯åå†è¿è¡Œå®Œæ•´æœç´¢ã€‚

### 2. åˆ†é˜¶æ®µæ‰§è¡Œ

å¦‚æœæ‹…å¿ƒå®Œæ•´æœç´¢æ—¶é—´è¿‡é•¿ï¼Œå¯ä»¥åˆ†é˜¶æ®µæ‰§è¡Œï¼š

```bash
# é˜¶æ®µ1ï¼šåªåšç²—ç²’åº¦æœç´¢ï¼ˆæ‰‹åŠ¨ï¼‰
for dist in 0:10 1:9 2:8 3:7 4:6 5:5 6:4 7:3 8:2 9:1 10:0; do
    python llama3_unbalanced_pruning_gqa_aware.py \
        --pruning_distribution $dist \
        --test_after_prune
done

# åˆ†æç»“æœï¼Œæ‰¾åˆ°æœ€ä¼˜åŒºé—´

# é˜¶æ®µ2ï¼šåœ¨æœ€ä¼˜åŒºé—´ç»†åŒ–æœç´¢
for i in {1..9}; do
    ratio=$(echo "scale=1; $i/10" | bc)
    ratio2=$(echo "scale=1; 10-$ratio" | bc)
    python llama3_unbalanced_pruning_gqa_aware.py \
        --pruning_distribution ${ratio}:${ratio2} \
        --test_after_prune
done
```

### 3. å¹¶è¡ŒåŠ é€Ÿ

å¦‚æœæœ‰å¤šä¸ªGPUï¼Œå¯ä»¥æ‰‹åŠ¨å¹¶è¡Œï¼š

```bash
# GPU 0: æµ‹è¯• 0:10 åˆ° 5:5
CUDA_VISIBLE_DEVICES=0 python search_optimal_distribution.py \
    --base_model /path/to/model \
    --save_ckpt_log_name search_gpu0 &

# GPU 1: æ‰‹åŠ¨æµ‹è¯•å…¶ä»–æ¯”ä¾‹
CUDA_VISIBLE_DEVICES=1 python llama3_unbalanced_pruning_gqa_aware.py \
    --pruning_distribution 6:4 \
    --test_after_prune &

# ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
wait
```

### 4. ç›‘æ§è¿›åº¦

æœç´¢è¿‡ç¨‹ä¸­å¯ä»¥å®æ—¶æŸ¥çœ‹è¿›åº¦ï¼š

```bash
# æŸ¥çœ‹å½“å‰æœç´¢æ—¥å¿—
tail -f prune_log/my_ppl_search/search.log

# æŸ¥çœ‹å·²å®Œæˆçš„ç»“æœ
cat prune_log/my_ppl_search/search_results.json | python -m json.tool
```

---

## æ•…éšœæ’é™¤

### é—®é¢˜1ï¼šæœç´¢å¡ä½ä¸åŠ¨

**ç—‡çŠ¶**ï¼šé•¿æ—¶é—´æ²¡æœ‰è¾“å‡º

**è§£å†³æ–¹æ³•**ï¼š
1. æ£€æŸ¥æ˜¯å¦æœ‰GPUèµ„æºè¢«å ç”¨
2. æŸ¥çœ‹å­è¿›ç¨‹æ—¥å¿—ï¼š`tail -f prune_log/<experiment_name>/ratio_*/*/training.log`
3. æ£€æŸ¥å†…å­˜æ˜¯å¦ä¸è¶³ï¼ˆOOMï¼‰

### é—®é¢˜2ï¼šPPLæå–å¤±è´¥

**ç—‡çŠ¶**ï¼šçœ‹åˆ° "âŒ æ— æ³•ä»è¾“å‡ºä¸­æå–PPL"

**è§£å†³æ–¹æ³•**ï¼š
1. æ£€æŸ¥å­å®éªŒçš„æ—¥å¿—ï¼ŒæŸ¥çœ‹æ˜¯å¦æˆåŠŸè¿è¡Œ
2. ç¡®è®¤ä½¿ç”¨äº† `--test_after_prune` å‚æ•°
3. æ‰‹åŠ¨è¿è¡Œä¸€æ¬¡å‰ªæè„šæœ¬ï¼Œç¡®è®¤PPLè¾“å‡ºæ ¼å¼

### é—®é¢˜3ï¼šä¸­é€”ä¸­æ–­åå¦‚ä½•æ¢å¤

**æ–¹æ³•**ï¼š
1. æŸ¥çœ‹ `search_results.json`ï¼Œç¡®è®¤å·²å®Œæˆçš„æ¯”ä¾‹
2. æ‰‹åŠ¨è¡¥å……æœªå®Œæˆçš„æ¯”ä¾‹æµ‹è¯•
3. åˆå¹¶ç»“æœåˆ°åŒä¸€ä¸ªJSONæ–‡ä»¶

---

## æ€§èƒ½ä¼˜åŒ–å»ºè®®

| ä¼˜åŒ–æ–¹æ³• | æ—¶é—´èŠ‚çœ | å‡†ç¡®æ€§å½±å“ |
|---------|---------|-----------|
| å‡å°‘ `layer_importance_samples` (50â†’20) | ~30% | å° |
| å‡å°‘ `channel_importance_samples` (10â†’5) | ~20% | å° |
| è·³è¿‡å±‚é‡è¦æ€§åˆ†æï¼ˆå¤ç”¨é…ç½®ï¼‰ | ~40% | æ— ï¼ˆéœ€å…ˆè¿è¡Œä¸€æ¬¡ï¼‰ |
| ä½¿ç”¨æ›´å¿«çš„GPUï¼ˆA100 vs V100ï¼‰ | ~50% | æ—  |
| å¤šGPUå¹¶è¡Œï¼ˆæ‰‹åŠ¨åˆ†é…ï¼‰ | ~2-4x | æ—  |

**æ¨èé…ç½®**ï¼ˆå¿«é€Ÿæµ‹è¯•ï¼‰ï¼š
```bash
python search_optimal_distribution.py \
    --base_model /path/to/model \
    --layer_importance_samples 20 \
    --channel_importance_samples 5
```

**æ¨èé…ç½®**ï¼ˆç”Ÿäº§ç¯å¢ƒï¼‰ï¼š
```bash
python search_optimal_distribution.py \
    --base_model /path/to/model \
    --layer_importance_samples 50 \
    --channel_importance_samples 10
```

---

## æ€»ç»“

è‡ªåŠ¨æœç´¢è„šæœ¬å¯ä»¥å¤§å¹…ç®€åŒ–æœ€ä¼˜å‰ªææ¯”ä¾‹çš„å¯»æ‰¾è¿‡ç¨‹ï¼š

âœ… **ä¼˜ç‚¹**ï¼š
- å…¨è‡ªåŠ¨åŒ–ï¼Œæ— éœ€äººå·¥å¹²é¢„
- ä¸¤é˜¶æ®µç­–ç•¥é«˜æ•ˆä¸”ç²¾ç¡®
- ç»“æœå¯å¤ç°ï¼Œä¿å­˜å®Œæ•´å†å²

âš ï¸ **æ³¨æ„**ï¼š
- å®Œæ•´æœç´¢éœ€è¦æ•°å°æ—¶
- å»ºè®®å…ˆéªŒè¯æµç¨‹å†è¿è¡Œ
- å¯ä»¥éšæ—¶ä¸­æ–­ï¼Œç»“æœå·²ä¿å­˜

ğŸ¯ **é€‚ç”¨åœºæ™¯**ï¼š
- æ–°æ¨¡å‹é¦–æ¬¡å‰ªæï¼Œä¸ç¡®å®šæœ€ä¼˜æ¯”ä¾‹
- å¯¹æ¯”ä¸åŒå‰ªæç‡æˆ–å±‚å†»ç»“é…ç½®
- éœ€è¦ç³»ç»Ÿæ€§æ¢ç´¢å‚æ•°ç©ºé—´

ç¥æ‚¨æ‰¾åˆ°æœ€ä¼˜çš„å‰ªæé…ç½®ï¼ğŸ‰
